# Enhanced Kafka Topics Configuration
# Includes topics for Google Research integration

# Original platform topics
topics:
  # Fire risk and prediction topics
  - name: fire-risk-alerts
    partitions: 6
    replication_factor: 1
    config:
      retention.ms: 604800000  # 7 days
      cleanup.policy: delete
      compression.type: snappy

  - name: fire-prediction-requests
    partitions: 8
    replication_factor: 1
    config:
      retention.ms: 86400000   # 24 hours
      cleanup.policy: delete
      compression.type: gzip

  - name: fire-prediction-results
    partitions: 8
    replication_factor: 1
    config:
      retention.ms: 2592000000 # 30 days
      cleanup.policy: delete
      compression.type: snappy

  # Data ingestion topics
  - name: sensor-data-raw
    partitions: 12
    replication_factor: 1
    config:
      retention.ms: 259200000  # 3 days
      cleanup.policy: delete
      compression.type: lz4

  - name: weather-data
    partitions: 4
    replication_factor: 1
    config:
      retention.ms: 604800000  # 7 days
      cleanup.policy: delete

  - name: satellite-imagery-metadata
    partitions: 6
    replication_factor: 1
    config:
      retention.ms: 2592000000 # 30 days
      cleanup.policy: delete

  # Google Research integration topics
  
  # FireBench simulation data
  - name: firebench-simulation-data
    partitions: 12
    replication_factor: 1
    config:
      retention.ms: 2592000000  # 30 days for simulation data
      cleanup.policy: delete
      compression.type: snappy
      segment.ms: 3600000       # 1 hour segments
      max.message.bytes: 10485760  # 10MB for large simulation datasets

  - name: firebench-scenarios
    partitions: 4
    replication_factor: 1
    config:
      retention.ms: 7776000000  # 90 days for scenario metadata
      cleanup.policy: compact    # Keep latest scenario configuration
      compression.type: gzip

  # FireSat satellite detection data
  - name: firesat-detections
    partitions: 6
    replication_factor: 1
    config:
      retention.ms: 604800000   # 7 days for satellite detections
      cleanup.policy: delete
      compression.type: snappy
      max.message.bytes: 5242880  # 5MB for detection images

  - name: firesat-realtime-alerts
    partitions: 3
    replication_factor: 1
    config:
      retention.ms: 86400000    # 24 hours for real-time alerts
      cleanup.policy: delete
      compression.type: gzip
      min.insync.replicas: 1    # Ensure alert delivery

  - name: firesat-constellation-status
    partitions: 1
    replication_factor: 1
    config:
      retention.ms: 604800000   # 7 days
      cleanup.policy: compact   # Keep latest status from each satellite
      compression.type: gzip

  # AI Boundary Tracking data
  - name: fire-boundary-tracking
    partitions: 8
    replication_factor: 1
    config:
      retention.ms: 2592000000  # 30 days for boundary history
      cleanup.policy: delete
      compression.type: snappy
      max.message.bytes: 20971520  # 20MB for boundary polygons and confidence maps

  - name: boundary-change-detection
    partitions: 4
    replication_factor: 1
    config:
      retention.ms: 604800000   # 7 days
      cleanup.policy: delete
      compression.type: gzip

  - name: ai-model-predictions
    partitions: 6
    replication_factor: 1
    config:
      retention.ms: 1209600000  # 14 days
      cleanup.policy: delete
      compression.type: snappy

  # Enhanced ML model topics
  - name: enhanced-fire-predictions
    partitions: 10
    replication_factor: 1
    config:
      retention.ms: 2592000000  # 30 days
      cleanup.policy: delete
      compression.type: snappy
      max.message.bytes: 15728640  # 15MB for 3D risk fields

  - name: ml-model-training-data
    partitions: 8
    replication_factor: 1
    config:
      retention.ms: 7776000000  # 90 days for training datasets
      cleanup.policy: delete
      compression.type: gzip
      segment.bytes: 1073741824  # 1GB segments

  - name: model-performance-metrics
    partitions: 2
    replication_factor: 1
    config:
      retention.ms: 7776000000  # 90 days
      cleanup.policy: compact   # Keep latest metrics per model
      compression.type: gzip

  # Large Eddy Simulation (LES) topics
  - name: les-simulation-requests
    partitions: 4
    replication_factor: 1
    config:
      retention.ms: 86400000    # 24 hours
      cleanup.policy: delete
      compression.type: gzip

  - name: les-simulation-results
    partitions: 6
    replication_factor: 1
    config:
      retention.ms: 2592000000  # 30 days
      cleanup.policy: delete
      compression.type: snappy
      max.message.bytes: 52428800  # 50MB for large simulation results

  - name: les-flow-fields
    partitions: 8
    replication_factor: 1
    config:
      retention.ms: 604800000   # 7 days
      cleanup.policy: delete
      compression.type: lz4     # Fast compression for flow field data
      max.message.bytes: 104857600  # 100MB for 3D flow fields

  # Real-time processing pipeline topics
  - name: realtime-fire-analysis
    partitions: 12
    replication_factor: 1
    config:
      retention.ms: 172800000   # 2 days
      cleanup.policy: delete
      compression.type: snappy

  - name: multi-source-data-fusion
    partitions: 8
    replication_factor: 1
    config:
      retention.ms: 259200000   # 3 days
      cleanup.policy: delete
      compression.type: gzip

  - name: prediction-pipeline-metrics
    partitions: 2
    replication_factor: 1
    config:
      retention.ms: 604800000   # 7 days
      cleanup.policy: compact
      compression.type: gzip

  # Google Research partnership topics
  - name: google-research-collaboration
    partitions: 4
    replication_factor: 1
    config:
      retention.ms: 7776000000  # 90 days
      cleanup.policy: delete
      compression.type: gzip

  - name: earth-fire-alliance-updates
    partitions: 2
    replication_factor: 1
    config:
      retention.ms: 2592000000  # 30 days
      cleanup.policy: compact
      compression.type: gzip

  # Data quality and validation topics
  - name: data-validation-results
    partitions: 4
    replication_factor: 1
    config:
      retention.ms: 604800000   # 7 days
      cleanup.policy: delete
      compression.type: gzip

  - name: quality-assurance-alerts
    partitions: 2
    replication_factor: 1
    config:
      retention.ms: 2592000000  # 30 days
      cleanup.policy: delete
      compression.type: gzip

  # External API integration topics
  - name: external-api-requests
    partitions: 6
    replication_factor: 1
    config:
      retention.ms: 86400000    # 24 hours
      cleanup.policy: delete
      compression.type: gzip

  - name: external-api-responses
    partitions: 6
    replication_factor: 1
    config:
      retention.ms: 259200000   # 3 days
      cleanup.policy: delete
      compression.type: snappy

  # System monitoring and health topics
  - name: service-health-checks
    partitions: 3
    replication_factor: 1
    config:
      retention.ms: 604800000   # 7 days
      cleanup.policy: compact   # Keep latest health status per service
      compression.type: gzip

  - name: performance-monitoring
    partitions: 4
    replication_factor: 1
    config:
      retention.ms: 2592000000  # 30 days
      cleanup.policy: delete
      compression.type: gzip

  - name: error-tracking
    partitions: 3
    replication_factor: 1
    config:
      retention.ms: 604800000   # 7 days
      cleanup.policy: delete
      compression.type: gzip

# Topic naming conventions:
# - Use kebab-case for topic names
# - Include data source/type in name (firesat-, firebench-, etc.)
# - Use descriptive names indicating data flow direction
# - Group related topics with common prefixes

# Retention policies:
# - Real-time alerts: 24 hours (short retention for immediate action)
# - Operational data: 7 days (standard operational retention)
# - Historical analysis: 30 days (longer retention for analysis)
# - Training data: 90 days (extended retention for ML training)
# - Configuration data: Use compact cleanup for latest state

# Partitioning strategy:
# - High-throughput data streams: 8-12 partitions
# - Medium-throughput: 4-6 partitions  
# - Low-throughput/status: 1-3 partitions
# - Match consumer parallelism requirements

# Compression recommendations:
# - snappy: Good balance of speed/compression for most data
# - gzip: Better compression for text/json data
# - lz4: Fastest compression for high-throughput streams
# - No compression: Only for very low-latency requirements