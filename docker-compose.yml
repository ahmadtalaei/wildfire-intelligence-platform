services:
  # Infrastructure (Always works)
  postgres:
    image: postgis/postgis:15-3.4-alpine
    container_name: wildfire-postgres
    environment:
      POSTGRES_DB: ${POSTGRES_DB}
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./scripts/database:/docker-entrypoint-initdb.d:ro
    ports:
      - "5432:5432"
    networks:
      - wildfire-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U wildfire_user -d wildfire_db"]
      interval: 10s
      timeout: 5s
      retries: 5

  redis:
    image: redis:7-alpine
    container_name: wildfire-redis
    command: redis-server --requirepass ${REDIS_PASSWORD} --appendonly yes
    volumes:
      - redis_data:/data
    ports:
      - "6379:6379"
    networks:
      - wildfire-network
    restart: unless-stopped

  pgadmin:
    image: dpage/pgadmin4:latest
    container_name: wildfire-pgadmin
    environment:
      PGADMIN_DEFAULT_EMAIL: admin@wildfire.gov
      PGADMIN_DEFAULT_PASSWORD: admin123
      PGADMIN_CONFIG_SERVER_MODE: 'False'
    volumes:
      - pgadmin_data:/var/lib/pgadmin
    ports:
      - "5050:80"
    networks:
      - wildfire-network
    depends_on:
      - postgres
    restart: unless-stopped

  minio:
    image: minio/minio:latest
    container_name: wildfire-minio
    environment:
      MINIO_ROOT_USER: ${S3_ACCESS_KEY}
      MINIO_ROOT_PASSWORD: ${S3_SECRET_KEY}
    volumes:
      - minio_data:/data
    ports:
      - "9000:9000"
      - "9001:9001"
    networks:
      - wildfire-network
    command: server /data --console-address ":9001"
    restart: unless-stopped

  # Kafka Infrastructure
  zookeeper:
    image: confluentinc/cp-zookeeper:7.4.0
    container_name: wildfire-zookeeper
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    ports:
      - "2181:2181"
    networks:
      - wildfire-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "nc", "-z", "localhost", "2181"]
      interval: 10s
      timeout: 5s
      retries: 5

  kafka:
    image: confluentinc/cp-kafka:7.4.0
    container_name: wildfire-kafka
    depends_on:
      zookeeper:
        condition: service_healthy
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092,PLAINTEXT_HOST://localhost:29092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: true
      KAFKA_LOG_RETENTION_HOURS: 168
      KAFKA_LOG_RETENTION_BYTES: 1073741824
      # PERFORMANCE OPTIMIZATIONS for 10K-20K events/sec with 85 partitions
      KAFKA_NUM_NETWORK_THREADS: 8
      KAFKA_NUM_IO_THREADS: 16
      KAFKA_SOCKET_SEND_BUFFER_BYTES: 1048576  # 1MB
      KAFKA_SOCKET_RECEIVE_BUFFER_BYTES: 1048576  # 1MB
      KAFKA_SOCKET_REQUEST_MAX_BYTES: 104857600  # 100MB for large images
      # Compression support
      KAFKA_COMPRESSION_TYPE: gzip
      KAFKA_COMPRESSION_LEVEL: 6
      # Message size limits for binary images
      KAFKA_MESSAGE_MAX_BYTES: 20971520  # 20MB
      KAFKA_REPLICA_FETCH_MAX_BYTES: 20971520  # 20MB
      # Performance tuning for high partition count
      KAFKA_NUM_REPLICA_FETCHERS: 4
      KAFKA_NUM_PARTITIONS: 4  # Default for auto-created topics
      # Memory and buffer tuning
      KAFKA_REPLICA_SOCKET_RECEIVE_BUFFER_BYTES: 1048576
      # Log segment configuration for efficient storage
      KAFKA_LOG_SEGMENT_BYTES: 1073741824  # 1GB segments
      KAFKA_LOG_RETENTION_CHECK_INTERVAL_MS: 300000  # 5 minutes
    ports:
      - "9092:9092"
      - "29092:29092"
    networks:
      - wildfire-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "kafka-broker-api-versions", "--bootstrap-server", "localhost:9092"]
      interval: 10s
      timeout: 10s
      retries: 5
    volumes:
      - kafka_data:/var/lib/kafka/data

  # ==============================================================================
  # ADVANCED STREAMING & PROCESSING SERVICES
  # ==============================================================================

  # Confluent Schema Registry - Advanced Schema Management
  schema-registry:
    image: confluentinc/cp-schema-registry:7.5.0
    container_name: wildfire-schema-registry
    hostname: schema-registry
    restart: unless-stopped
    depends_on:
      kafka:
        condition: service_healthy
    ports:
      - "8082:8081"  # Changed from 8081 to 8082 to avoid conflict with Kong
    environment:
      SCHEMA_REGISTRY_HOST_NAME: schema-registry
      SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: kafka:29092
      SCHEMA_REGISTRY_LISTENERS: http://0.0.0.0:8081
      SCHEMA_REGISTRY_SCHEMA_COMPATIBILITY_LEVEL: BACKWARD_TRANSITIVE
      SCHEMA_REGISTRY_AVRO_COMPATIBILITY_LEVEL: BACKWARD_TRANSITIVE
      SCHEMA_REGISTRY_SCHEMA_CACHE_SIZE: 10000
      SCHEMA_REGISTRY_CACHE_CAPACITY: 1000
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8081/subjects"]
      interval: 30s
      timeout: 10s
      retries: 5
    networks:
      - wildfire-network
    volumes:
      - schema-registry-secrets:/etc/schema-registry/secrets

  # Kafka Streams Processor - Stateful Stream Processing with CEP
  # DISABLED: kafka-streams-processor (incomplete - missing dependencies)
  # kafka-streams-processor:
  #   build:
  #     context: ./services/kafka-streams-processor
  #     dockerfile: Dockerfile
  #   container_name: wildfire-kafka-streams
  #   restart: unless-stopped
  #   depends_on:
  #     kafka:
  #       condition: service_healthy
  #     schema-registry:
  #       condition: service_healthy
  #   environment:
  #     KAFKA_BOOTSTRAP_SERVERS: kafka:29092
  #     SCHEMA_REGISTRY_URL: http://schema-registry:8081
  #     APPLICATION_ID: wildfire-stream-processor
  #     STATE_DIR: /var/kafka-streams
  #     CACHE_MAX_BYTES_BUFFERING: 536870912
  #     COMMIT_INTERVAL_MS: 1000
  #     NUM_STREAM_THREADS: 4
  #     PROCESSING_GUARANTEE: exactly_once_v2
  #     TUMBLING_WINDOW_SIZE_MS: 60000
  #     SESSION_WINDOW_GAP_MS: 300000
  #     INPUT_TOPICS: wildfire-iot-sensors,wildfire-nasa-firms,wildfire-weather-data
  #     OUTPUT_TOPIC: wildfire-processed-events
  #     REDIS_HOST: redis
  #     REDIS_PORT: 6379
  #   volumes:
  #     - kafka-streams-state:/var/kafka-streams
  #     - ./services/kafka-streams-processor/src:/app
  #   ports:
  #     - "8091:8090"
  #   networks:
  #     - wildfire-network
  #   deploy:
  #     resources:
  #       limits:
  #         memory: 2G
  #       reservations:
  #         memory: 1G

  # Debezium CDC Connector - Change Data Capture
  debezium-connect:
    image: debezium/connect:2.4
    container_name: wildfire-debezium
    restart: unless-stopped
    depends_on:
      kafka:
        condition: service_healthy
      postgres:
        condition: service_healthy
    ports:
      - "8083:8083"
    environment:
      BOOTSTRAP_SERVERS: kafka:29092
      GROUP_ID: wildfire-connect-group
      CONFIG_STORAGE_TOPIC: wildfire-connect-configs
      OFFSET_STORAGE_TOPIC: wildfire-connect-offsets
      STATUS_STORAGE_TOPIC: wildfire-connect-status
      CONFIG_STORAGE_REPLICATION_FACTOR: 1
      OFFSET_STORAGE_REPLICATION_FACTOR: 1
      STATUS_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_PRODUCER_BATCH_SIZE: 32768
      CONNECT_PRODUCER_LINGER_MS: 100
      CONNECT_PRODUCER_COMPRESSION_TYPE: gzip
      CONNECT_KEY_CONVERTER: io.confluent.connect.avro.AvroConverter
      CONNECT_VALUE_CONVERTER: io.confluent.connect.avro.AvroConverter
      CONNECT_KEY_CONVERTER_SCHEMA_REGISTRY_URL: http://schema-registry:8081
      CONNECT_VALUE_CONVERTER_SCHEMA_REGISTRY_URL: http://schema-registry:8081
      CONNECT_EXACTLY_ONCE_SUPPORT: enabled
      CONNECT_TRANSACTION_ISOLATION_LEVEL: read_committed
    networks:
      - wildfire-network
    volumes:
      - ./services/cdc-connector/config:/kafka/config

  # Weaviate Vector Database - ML Similarity Search
  weaviate:
    image: semitechnologies/weaviate:1.22.4
    container_name: wildfire-vector-db
    restart: unless-stopped
    ports:
      - "8088:8080"
      - "50051:50051"
    environment:
      QUERY_DEFAULTS_LIMIT: 25
      AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: 'true'
      PERSISTENCE_DATA_PATH: '/var/lib/weaviate'
      DEFAULT_VECTORIZER_MODULE: 'text2vec-transformers'
      ENABLE_MODULES: 'text2vec-transformers,text2vec-openai'
      TRANSFORMERS_INFERENCE_API: 'http://text2vec-transformers:8080'
      CLUSTER_HOSTNAME: 'weaviate'
      GODEBUG: 'madvdontneed=1'
      GOMAXPROCS: 4
    volumes:
      - weaviate-data:/var/lib/weaviate
    networks:
      - wildfire-network
    deploy:
      resources:
        limits:
          memory: 2G
        reservations:
          memory: 1G

  # Transformer Model for Vector Embeddings
  text2vec-transformers:
    image: semitechnologies/transformers-inference:sentence-transformers-all-MiniLM-L6-v2
    container_name: wildfire-text2vec
    restart: unless-stopped
    environment:
      ENABLE_CUDA: 0
    networks:
      - wildfire-network

  # Jaeger - Distributed Tracing
  jaeger:
    image: jaegertracing/all-in-one:1.52
    container_name: wildfire-jaeger
    restart: unless-stopped
    ports:
      - "5775:5775/udp"
      - "6831:6831/udp"
      - "6832:6832/udp"
      - "5778:5778"
      - "16686:16686"
      - "14250:14250"
      - "14268:14268"
      - "14269:14269"
    environment:
      COLLECTOR_OTLP_ENABLED: true
      SPAN_STORAGE_TYPE: badger
      BADGER_EPHEMERAL: false
      BADGER_DIRECTORY_VALUE: /badger/data
      BADGER_DIRECTORY_KEY: /badger/key
    volumes:
      - jaeger-badger-data:/badger
    networks:
      - wildfire-network

  # OpenTelemetry Collector - Metrics & Traces Collection
  otel-collector:
    image: otel/opentelemetry-collector-contrib:0.91.0
    container_name: wildfire-otel-collector
    restart: unless-stopped
    ports:
      - "4317:4317"
      - "4318:4318"
      - "8889:8889"
      - "13133:13133"
    environment:
      - JAEGER_ENDPOINT=http://jaeger:14250
      - PROMETHEUS_ENDPOINT=http://prometheus:9090
    volumes:
      - ./services/tracing/otel-config.yaml:/etc/otel-collector-config.yaml
    command: ["--config", "/etc/otel-collector-config.yaml"]
    networks:
      - wildfire-network
    depends_on:
      - jaeger

  # KSQLDB - Stream Processing with SQL
  ksqldb-server:
    image: confluentinc/ksqldb-server:0.29.0
    container_name: wildfire-ksqldb
    restart: unless-stopped
    depends_on:
      kafka:
        condition: service_healthy
      schema-registry:
        condition: service_healthy
    ports:
      - "8089:8088"
    environment:
      KSQL_LISTENERS: http://0.0.0.0:8088
      KSQL_BOOTSTRAP_SERVERS: kafka:29092
      KSQL_SCHEMA_REGISTRY_URL: http://schema-registry:8081
      KSQL_KSQL_LOGGING_PROCESSING_STREAM_AUTO_CREATE: "true"
      KSQL_KSQL_LOGGING_PROCESSING_TOPIC_AUTO_CREATE: "true"
      KSQL_KSQL_STREAMS_REPLICATION_FACTOR: 1
      KSQL_KSQL_INTERNAL_TOPIC_REPLICAS: 1
      KSQL_KSQL_STREAMS_NUM_STREAM_THREADS: 4
      KSQL_KSQL_STREAMS_CACHE_MAX_BYTES_BUFFERING: 536870912
      KSQL_KSQL_STREAMS_PROCESSING_GUARANTEE: exactly_once_v2
      KSQL_KSQL_STREAMS_STATE_DIR: /var/ksqldb
    volumes:
      - ksqldb-data:/var/ksqldb
    networks:
      - wildfire-network

  # ==============================================================================
  # ADVANCED KAFKA OPTIMIZATION SERVICES (5-7x Performance Improvement)
  # ==============================================================================

  # Dynamic Partition Manager - Auto-scaling partitions based on lag
  dynamic-partition-manager:
    build:
      context: ./services/dynamic-partition-manager
      dockerfile: Dockerfile
    container_name: wildfire-partition-manager
    restart: unless-stopped
    depends_on:
      kafka:
        condition: service_healthy
      redis:
        condition: service_started
    environment:
      KAFKA_BOOTSTRAP_SERVERS: kafka:29092
      REDIS_HOST: redis
      REDIS_PORT: 6379
      PYTHONUNBUFFERED: 1
    ports:
      - "9091:9091"
    networks:
      - wildfire-network
    deploy:
      resources:
        limits:
          memory: 512M
        reservations:
          memory: 256M

  # Tiered Storage - S3 offloading for large messages (90% broker load reduction)
  kafka-tiered-storage:
    build:
      context: ./services/kafka-tiered-storage
      dockerfile: Dockerfile
    container_name: wildfire-tiered-storage
    restart: unless-stopped
    depends_on:
      kafka:
        condition: service_healthy
      minio:
        condition: service_started
      redis:
        condition: service_started
    environment:
      KAFKA_BOOTSTRAP_SERVERS: kafka:29092
      MINIO_ENDPOINT: minio:9000
      MINIO_ACCESS_KEY: minioadmin
      MINIO_SECRET_KEY: minioadminpassword
      REDIS_HOST: redis
      REDIS_PORT: 6379
      USE_AWS_S3: 'false'
      AWS_REGION: us-west-1
      PYTHONUNBUFFERED: 1
    ports:
      - "9096:9092"
    networks:
      - wildfire-network
    deploy:
      resources:
        limits:
          memory: 1G
        reservations:
          memory: 512M

  # Consumer Autoscaler - Dynamic consumer scaling based on lag
  consumer-autoscaler:
    build:
      context: ./services/consumer-autoscaler
      dockerfile: Dockerfile
    container_name: wildfire-consumer-autoscaler
    restart: unless-stopped
    depends_on:
      kafka:
        condition: service_healthy
      redis:
        condition: service_started
    environment:
      KAFKA_BOOTSTRAP_SERVERS: kafka:29092
      REDIS_HOST: redis
      REDIS_PORT: 6379
      K8S_NAMESPACE: default
      PYTHONUNBUFFERED: 1
    ports:
      - "9093:9093"
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
    networks:
      - wildfire-network
    deploy:
      resources:
        limits:
          memory: 512M
        reservations:
          memory: 256M

  # MirrorMaker 2 Manager - Multi-cluster geo-replication
  mirrormaker2-manager:
    build:
      context: ./services/kafka-mirrormaker2
      dockerfile: Dockerfile
    container_name: wildfire-mirrormaker2
    restart: unless-stopped
    depends_on:
      kafka:
        condition: service_healthy
      redis:
        condition: service_started
    environment:
      KAFKA_NORCAL: kafka:29092
      KAFKA_SOCAL: kafka:29092
      KAFKA_CENTRAL: kafka:29092
      REDIS_HOST: redis
      REDIS_PORT: 6379
      PYTHONUNBUFFERED: 1
    ports:
      - "9094:9094"
    volumes:
      - ./services/kafka-mirrormaker2/config:/config:ro
    networks:
      - wildfire-network
    deploy:
      resources:
        limits:
          memory: 512M
        reservations:
          memory: 256M

  # Backpressure Controller - Advanced flow control and circuit breakers
  backpressure-controller:
    build:
      context: ./services/backpressure-manager
      dockerfile: Dockerfile
    container_name: wildfire-backpressure
    restart: unless-stopped
    depends_on:
      kafka:
        condition: service_healthy
      redis:
        condition: service_started
    environment:
      KAFKA_BOOTSTRAP_SERVERS: kafka:29092
      REDIS_HOST: redis
      REDIS_PORT: 6379
      PYTHONUNBUFFERED: 1
    ports:
      - "9095:9095"
    networks:
      - wildfire-network
    deploy:
      resources:
        limits:
          memory: 512M
        reservations:
          memory: 256M

  # ==============================================================================
  # MQTT Broker for IoT Sensors
  # ==============================================================================
  mosquitto:
    image: eclipse-mosquitto:2.0
    container_name: wildfire-mosquitto
    ports:
      - "1883:1883"
      - "9002:9001"
    volumes:
      - ./services/data-ingestion-service/config/mosquitto.conf:/mosquitto/config/mosquitto.conf:ro
      - ./services/data-ingestion-service/config/passwd:/mosquitto/config/passwd:ro
      - ./services/data-ingestion-service/config/acl:/mosquitto/config/acl:ro
      - mosquitto_data:/mosquitto/data
      - mosquitto_logs:/mosquitto/log
    command: mosquitto -c /mosquitto/config/mosquitto.conf
    networks:
      - wildfire-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "timeout", "5", "mosquitto_sub", "-t", "$$SYS/#", "-C", "1", "-i", "healthcheck"]
      interval: 10s
      timeout: 10s
      retries: 3

  # Working Backend Services
  data-storage-service:
    build: ./services/data-storage-service
    container_name: wildfire-data-storage
    environment:
      - DATABASE_URL=postgresql://wildfire_user:wildfire_password@postgres:5432/wildfire_db
      - TIMESCALE_URL=postgresql://wildfire_user:wildfire_password@postgres:5432/wildfire_db
      - REDIS_URL=redis://:redispassword@redis:6379/0
      - S3_ENDPOINT=http://minio:9000
      - S3_ACCESS_KEY=minioadmin
      - S3_SECRET_KEY=minioadminpassword
      - S3_BUCKET=wildfire-data
      - KAFKA_BOOTSTRAP_SERVERS=kafka:9092
      - KAFKA_CONSUMER_GROUP_ID=data-storage-consumer
      - KAFKA_AUTO_OFFSET_RESET=earliest
      - KAFKA_ENABLE_CONSUMER=true
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_started
      minio:
        condition: service_started
      kafka:
        condition: service_started
    ports:
      - "8001:8001"
    networks:
      - wildfire-network
    restart: unless-stopped

  fire-risk-service:
    build: ./services/fire-risk-service
    container_name: wildfire-fire-risk
    environment:
      - DATABASE_URL=postgresql://wildfire_user:wildfire_password@postgres:5432/wildfire_db
      - REDIS_URL=redis://:redispassword@redis:6379/0
      - DATA_STORAGE_URL=http://data-storage-service:8001
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_started
      data-storage-service:
        condition: service_started
    ports:
      - "8002:8002"
    networks:
      - wildfire-network
    restart: unless-stopped

  data-ingestion-service:
    build: ./services/data-ingestion-service
    container_name: wildfire-data-ingestion
    environment:
      - DATABASE_URL=postgresql://wildfire_user:wildfire_password@postgres:5432/wildfire_db
      - REDIS_URL=redis://:redispassword@redis:6379/0
      - DATA_STORAGE_URL=http://data-storage-service:8001
      - S3_ENDPOINT=http://minio:9000
      - S3_ACCESS_KEY=minioadmin
      - S3_SECRET_KEY=minioadminpassword
      - S3_BUCKET=wildfire-data
      - KAFKA_BOOTSTRAP_SERVERS=kafka:9092
      - KAFKA_COMPRESSION_TYPE=gzip
      - KAFKA_COMPRESSION_LEVEL=6
      - FIRMS_MAP_KEY=${FIRMS_MAP_KEY}
      - NOAA_USER_AGENT=${NOAA_USER_AGENT}
      - MQTT_BROKER_HOST=mosquitto
      - MQTT_BROKER_PORT=1883
      - MQTT_USERNAME=${MQTT_USERNAME}
      - MQTT_PASSWORD=${MQTT_PASSWORD}
      - MQTT_USE_SSL=${MQTT_USE_SSL}
      - PURPLEAIR_API_KEY=${PURPLEAIR_API_KEY}
      - AIRNOW_API_KEY=${AIRNOW_API_KEY}
      - CDSAPI_URL=${CDSAPI_URL}
      - CDSAPI_KEY=${CDSAPI_KEY}
      - COPERNICUS_CLIENT_ID=${COPERNICUS_CLIENT_ID}
      - COPERNICUS_CLIENT_SECRET=${COPERNICUS_CLIENT_SECRET}
      - COPERNICUS_USERNAME=${COPERNICUS_USERNAME}
      - COPERNICUS_PASSWORD=${COPERNICUS_PASSWORD}
      - USGS_USERNAME=${USGS_USERNAME}
      - USGS_PASSWORD=${USGS_PASSWORD}
      - USGS_API_KEY=${USGS_API_KEY}
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_started
      minio:
        condition: service_started
      kafka:
        condition: service_healthy
      mosquitto:
        condition: service_started
      data-storage-service:
        condition: service_started
    ports:
      - "8003:8003"
    networks:
      - wildfire-network
    restart: unless-stopped


  # Monitoring and Analytics Services
  metrics-monitoring-service:
    build: ./services/metrics-monitoring-service
    container_name: wildfire-metrics-monitoring
    environment:
      - DATA_INGESTION_URL=http://data-ingestion-service:8003
      - DATA_STORAGE_URL=http://data-storage-service:8001
      - FIRE_RISK_URL=http://fire-risk-service:8002
    depends_on:
      - data-ingestion-service
      - data-storage-service
      - fire-risk-service
    ports:
      - "8004:8004"
    networks:
      - wildfire-network
    restart: unless-stopped

  monitoring-data-generator:
    build: ./services/monitoring-data-generator
    container_name: wildfire-monitoring-data-generator
    environment:
      - POSTGRES_HOST=postgres
      - POSTGRES_PORT=5432
      - POSTGRES_DB=${POSTGRES_DB}
      - POSTGRES_USER=${POSTGRES_USER}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
    depends_on:
      postgres:
        condition: service_healthy
    networks:
      - wildfire-network
    restart: unless-stopped

  security-governance-service:
    build: ./services/security-governance-service
    container_name: wildfire-security-governance
    environment:
      - DATABASE_URL=postgresql://wildfire_user:wildfire_password@postgres:5432/wildfire_db
      - JWT_SECRET_KEY=your-super-secret-jwt-key-here
    depends_on:
      postgres:
        condition: service_healthy
    ports:
      - "8005:8005"
    networks:
      - wildfire-network
    restart: unless-stopped

  data-clearing-house:
    build: ./services/data-clearing-house
    container_name: wildfire-data-clearing-house
    environment:
      - DATABASE_URL=postgresql://wildfire_user:wildfire_password@postgres:5432/wildfire_db
      - DATA_STORAGE_URL=http://data-storage-service:8001
      - SECURITY_SERVICE_URL=http://security-governance-service:8005
    depends_on:
      postgres:
        condition: service_healthy
      data-storage-service:
        condition: service_started
      security-governance-service:
        condition: service_started
    ports:
      - "8006:8006"
    networks:
      - wildfire-network
    restart: unless-stopped

  # Frontend Applications
  # Main URL - System Overview (Port 3000)
  main-frontend:
    image: nginx:alpine
    container_name: wildfire-main-frontend
    volumes:
      - ./frontend/simple-static:/usr/share/nginx/html:ro
    ports:
      - "3000:80"
    networks:
      - wildfire-network
    restart: unless-stopped

  # Fire Chief Dashboard - Port 3001
  fire-chief-dashboard:
    image: nginx:alpine
    container_name: wildfire-fire-chief-dashboard
    volumes:
      - ./frontend/fire-chief-dashboard/build:/usr/share/nginx/html:ro
      - ./frontend/fire-chief-dashboard/nginx.conf:/etc/nginx/conf.d/default.conf:ro
    ports:
      - "3001:80"
    networks:
      - wildfire-network
    restart: unless-stopped
    depends_on:
      - data-storage-service

  # Data Analyst Portal - Port 3002
  analyst-portal:
    image: nginx:alpine
    container_name: wildfire-analyst-portal
    volumes:
      - ./frontend/analyst-portal:/usr/share/nginx/html:ro
    ports:
      - "3002:80"
    networks:
      - wildfire-network
    restart: unless-stopped

  # Scientist Workbench - Port 3003  
  scientist-workbench:
    image: nginx:alpine
    container_name: wildfire-scientist-workbench
    volumes:
      - ./frontend/scientist-workbench:/usr/share/nginx/html:ro
    ports:
      - "3003:80"
    networks:
      - wildfire-network
    restart: unless-stopped

  # Admin Console - Port 3004
  admin-console:
    image: nginx:alpine
    container_name: wildfire-admin-console
    volumes:
      - ./frontend/admin-console:/usr/share/nginx/html:ro
    ports:
      - "3004:80"
    networks:
      - wildfire-network
    restart: unless-stopped

  # System Management Services
  
  # Grafana - System Monitoring
  grafana:
    image: grafana/grafana:latest
    container_name: wildfire-grafana
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_ADMIN_PASSWORD}
      - GF_USERS_ALLOW_SIGN_UP=${GRAFANA_ALLOW_SIGNUP}
    volumes:
      - grafana_data:/var/lib/grafana
      - ./monitoring/grafana/datasources:/etc/grafana/provisioning/datasources
      - ./monitoring/grafana/dashboards:/etc/grafana/provisioning/dashboards
    ports:
      - "3010:3000"
    networks:
      - wildfire-network
    restart: unless-stopped
    depends_on:
      - prometheus
      - postgres

  # Prometheus - Metrics Collection
  prometheus:
    image: prom/prometheus:latest
    container_name: wildfire-prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--storage.tsdb.retention.time=200h'
      - '--web.enable-lifecycle'
    volumes:
      - ./monitoring/prometheus:/etc/prometheus
      - prometheus_data:/prometheus
    ports:
      - "9090:9090"
    networks:
      - wildfire-network
    restart: unless-stopped
    depends_on:
      - node-exporter

  # Node Exporter - System Metrics (CPU, Memory, Disk)
  node-exporter:
    image: prom/node-exporter:latest
    container_name: wildfire-node-exporter
    command:
      - '--path.rootfs=/host'
      - '--collector.filesystem.mount-points-exclude=^/(sys|proc|dev|host|etc)($$|/)'
    volumes:
      - /proc:/host/proc:ro
      - /sys:/host/sys:ro
      - /:/rootfs:ro
    ports:
      - "9100:9100"
    networks:
      - wildfire-network
    restart: unless-stopped
    privileged: true

  # Elasticsearch - Log Storage
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.15.0
    container_name: wildfire-elasticsearch
    environment:
      - discovery.type=single-node
      - ES_JAVA_OPTS=-Xms512m -Xmx512m
      - xpack.security.enabled=false
      - xpack.security.enrollment.enabled=false
    volumes:
      - elasticsearch_data:/usr/share/elasticsearch/data
    ports:
      - "9200:9200"
    networks:
      - wildfire-network
    restart: unless-stopped

  # Kibana - Log Analysis
  kibana:
    image: docker.elastic.co/kibana/kibana:8.15.0
    container_name: wildfire-kibana
    environment:
      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
    ports:
      - "5601:5601"
    networks:
      - wildfire-network
    restart: unless-stopped
    depends_on:
      - elasticsearch

  # Kong - API Gateway
  kong:
    image: kong:3.7
    container_name: wildfire-kong
    environment:
      - KONG_DATABASE=off
      - KONG_DECLARATIVE_CONFIG=/kong/declarative/kong.yml
      - KONG_PROXY_ACCESS_LOG=/dev/stdout
      - KONG_ADMIN_ACCESS_LOG=/dev/stdout
      - KONG_PROXY_ERROR_LOG=/dev/stderr
      - KONG_ADMIN_ERROR_LOG=/dev/stderr
      - KONG_ADMIN_LISTEN=0.0.0.0:8001
      - KONG_ADMIN_GUI_URL=http://localhost:8080
    volumes:
      - ./monitoring/kong:/kong/declarative
    ports:
      - "8080:8000"
      - "8443:8443"
      - "8081:8001"
      - "8444:8444"
    networks:
      - wildfire-network
    restart: unless-stopped

  # Apache Airflow - Workflow Orchestration
  airflow-webserver:
    image: apache/airflow:2.10.2-python3.10
    container_name: wildfire-airflow-webserver
    environment:
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://wildfire_user:wildfire_password@postgres/airflow_db
      - AIRFLOW__CORE__FERNET_KEY=81HqDtbqAywKSOumSha3BhWNOdQ26slT6K0YaZeZyPs=
      - AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION=true
      - AIRFLOW__CORE__LOAD_EXAMPLES=false
      - AIRFLOW__WEBSERVER__SECRET_KEY=wildfire_secret_key_change_in_production
      - AIRFLOW__WEBSERVER__EXPOSE_CONFIG=true
      - AIRFLOW_CONN_POSTGRES_DEFAULT=postgresql://wildfire_user:wildfire_password@postgres:5432/wildfire_db
      - AIRFLOW_CONN_MINIO_DEFAULT=s3://minioadmin:minioadminpassword@minio:9000
      - _AIRFLOW_DB_MIGRATE=true
      - _AIRFLOW_WWW_USER_CREATE=true
      - _AIRFLOW_WWW_USER_USERNAME=admin
      - _AIRFLOW_WWW_USER_PASSWORD=admin123
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./airflow/logs:/opt/airflow/logs
      - ./airflow/plugins:/opt/airflow/plugins
      - ./airflow/config:/opt/airflow/config
      - airflow_data:/opt/airflow
    ports:
      - "8090:8080"
    networks:
      - wildfire-network
    depends_on:
      postgres:
        condition: service_healthy
    restart: unless-stopped
    command: webserver
    healthcheck:
      test: ["CMD", "curl", "--fail", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 5

  airflow-scheduler:
    image: apache/airflow:2.10.2-python3.10
    container_name: wildfire-airflow-scheduler
    environment:
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://wildfire_user:wildfire_password@postgres/airflow_db
      - AIRFLOW__CORE__FERNET_KEY=81HqDtbqAywKSOumSha3BhWNOdQ26slT6K0YaZeZyPs=
      - AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION=false
      - AIRFLOW__CORE__LOAD_EXAMPLES=false
      - AIRFLOW_CONN_POSTGRES_DEFAULT=postgresql://wildfire_user:wildfire_password@postgres:5432/wildfire_db
      - AIRFLOW_CONN_MINIO_DEFAULT=s3://minioadmin:minioadminpassword@minio:9000
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./airflow/logs:/opt/airflow/logs
      - ./airflow/plugins:/opt/airflow/plugins
      - ./airflow/config:/opt/airflow/config
      - airflow_data:/opt/airflow
    networks:
      - wildfire-network
    depends_on:
      postgres:
        condition: service_healthy
    restart: unless-stopped
    command: scheduler
    healthcheck:
      test: ["CMD", "airflow", "jobs", "check", "--job-type", "SchedulerJob"]
      interval: 30s
      timeout: 10s
      retries: 5

  # Best Practices Initialization Service
  # This service runs once on startup to initialize all production features
  best-practices-init:
    image: docker:27-cli
    container_name: wildfire-best-practices-init
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock:ro
      - ./scripts:/scripts:ro
    networks:
      - wildfire-network
    depends_on:
      postgres:
        condition: service_healthy
      kafka:
        condition: service_healthy
      data-ingestion-service:
        condition: service_started
      airflow-scheduler:
        condition: service_started
    command: sh /scripts/init-all-best-practices.sh
    restart: on-failure

volumes:
  postgres_data:
  redis_data:
  minio_data:
  kafka_data:
  grafana_data:
  prometheus_data:
  elasticsearch_data:
  pgadmin_data:
  mosquitto_data:
  mosquitto_logs:
  airflow_data:
  # Advanced services volumes
  schema-registry-secrets:
  kafka-streams-state:
  weaviate-data:
  jaeger-badger-data:
  ksqldb-data:

networks:
  wildfire-network:
    driver: bridge