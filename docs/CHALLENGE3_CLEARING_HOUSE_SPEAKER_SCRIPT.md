# Challenge 3: Global Wildfire Intelligence Data Clearing House Portal

## Setup Instructions - Before We Begin

Welcome to the Challenge Three demonstration for the Data Clearing House…

Before we explore the features… let me walk you through how to access this portal…

First… ensure that all Docker services are running…

You can verify this by opening a terminal and running docker dash ps to confirm that the wildfire-data-clearing-house service is active…

Once the services are confirmed running… open your web browser…

Navigate to localhost port eight thousand six…

The Data Clearing House portal homepage will load immediately… no login credentials are required for this public-facing interface…

You'll see the main portal page with statistics, navigation buttons, and feature cards.


## Demonstration Context and Data Disclaimer

Before we begin the walkthrough… please note an important context about this demonstration…

The statistics and data values you will see in this portal represent demonstration for the purposes of this presentation…

For example… the specific numerical values shown… such as total datasets available, number of countries served, and terabytes of data shared… are sample values that would be dynamically calculated from live database queries in a production deployment…

The platform architecture, security features, and technical capabilities you'll observe are production-ready and fully functional…

With that context established… let's explore the Data Clearing House portal.


## Portal Overview

This is the public-facing portal for Challenge Three… the data consumption and presentation layer of our platform…

It serves as the unified gateway for international fire agencies, research institutions, and emergency responders to access real-time wildfire data and analytics.


## Statistics Bar

Just below the header… we have a statistics bar showing four key metrics…

Datasets Available represents the number of curated datasets currently accessible through the platform… including fire detections, weather data, and risk models…

Next… Partner Agencies...

These are the international fire management organizations we're actively collaborating with… sharing data and best practices…

Then… Countries Served which indicates our global reach… 

Finally… on the right… Data Shared shows one point three Terabytes…

That represents satellite imagery, weather observations, and fire incident records shared with partner agencies…

These numbers animate when the page loads… counting up from zero to emphasize the scale of the data sharing operation.


## Navigation Buttons

Below… we see four main navigation buttons arranged horizontally…

The first button… Data Catalog… takes users to a searchable inventory of all available datasets… 

This is where analysts can browse fire detections, weather data, and satellite imagery… filtering by date, location, or data type…


Next… Analytics Portal… provides access to interactive visualization tools…

Users can create custom charts, maps, and reports… exploring trends in fire activity across regions and time periods…

Below the controls… a grid of four interactive charts displays the analysis results…

In the top-left… the first chart displays a line graph showing monthly fire incidents… and the number of fire incidents…

on the right… we have a Geographic Distribution chart…

This shows an interactive map of the United States… 

The size and color of each circle represent the fire activity intensity in that region…

Users can hover over points to see exact fire counts and locations… making it easy to identify hotspots.


Bottom-left… the Risk Assessment Model chart displays a pie chart…

It breaks down fire risk levels into four categories… Low risk in green at thirty-five percent… Moderate risk in orange at twenty-eight percent… High risk in darker orange at twenty-two percent… and Extreme risk in red at fifteen percent…

This gives fire managers a quick overview of current risk distribution across monitored areas.


Bottom-right… the Weather Correlation chart shows a scatter plot…

The scatter pattern reveals a clear correlation… higher temperatures correspond to more fire incidents… validating the importance of weather monitoring in fire prediction models.


All these charts are powered by Plotly JavaScript… allowing users to zoom, pan, and export visualizations as PNG images for reports…

The Analytics Portal connects to our multi-tier storage system… querying recent data from the HOT tier for near-real-time analysis… and historical data from WARM and COLD tiers for trend analysis.



The third button… API Documentation… links to technical specifications for developers with a Swagger UI interface…

This interactive API reference is auto-generated from our FastAPI backend…

The page is organized into sections… each representing a different API endpoint category.


The first section might be Datasets… showing endpoints like GET api datasets… which retrieves the list of all available datasets…

Clicking on an endpoint expands it to show detailed information…

We see the request parameters… such as query filters for data type, date range, and access level…

Below that… example request and response payloads are displayed in JSON format…

For example… a response might show an array of dataset objects… each with fields like name, description, size in megabytes, file format, and download URL…

There's also a Try it out button… allowing developers to test the API directly from the documentation… without writing any code.


Other sections include Authentication… explaining how to obtain API keys and JWT tokens…

Query Endpoints… showing how to execute custom SQL queries on the data warehouse…

Export Operations… documenting bulk data download capabilities in CSV, JSON, GeoJSON, and Parquet formats…

And Security… detailing rate limiting policies… encryption requirements… and audit logging.


This comprehensive API documentation enables external developers and researchers to integrate our wildfire intelligence into their own systems… building custom applications… mobile apps… and automated alert systems… all backed by our centralized data clearing house.

Finally… System Health… displays real-time status of our services…

Showing uptime, response times, and data freshness… so users know the platform is operating reliably.

In a production deployment… this health check endpoint would be monitored by our observability stack… with Prometheus scraping this endpoint every ten seconds… and alerting via PagerDuty if the status changes from healthy to degraded or unhealthy…

This simple JSON endpoint is critical for uptime monitoring… load balancer health checks… and automated incident response.


## Features Grid - Top Row

Below the navigation… we have a six-card grid showcasing platform capabilities…

The first card displays the title Real-Time Satellite Data…

This highlights one of our most valuable datasets… satellite-detected fire hotspots updated every few hours… allowing agencies to spot new fires quickly.

Below the statistics… we see individual satellite source cards… each with their own statistics and recent detection tables…


Next to it… The second card presents ML-Powered Analytics…

The text explains… Advanced machine learning models for fire risk prediction, behavior analysis, and resource optimization…

We're not just sharing raw data… we're providing trained models that predict where fires are likely to start… how they might spread… and where to position firefighting resources.



Moving to ML-Powered Analytics… this page showcases the machine learning models powering our fire intelligence…

The first card presents the Fire Risk Prediction Model…

Model Type indicates Random Forest Classifier…

Three performance metrics appear as green badges… These metrics demonstrate the model's ability to correctly identify areas at high risk of fire ignition…

The Features section explains the model uses weather conditions, vegetation index, historical patterns, and terrain slope as input variables…

Update Frequency shows Hourly predictions for seventy-two-hour forecast window…

This means fire managers get refreshed risk maps every hour… predicting fire danger three days into the future.


The second card is Fire Behavior Modeling…

Model Type shows Gradient Boosting plus Physical Models…

This indicates a hybrid approach… combining machine learning with traditional fire science equations…

Predictions include fire spread rate, direction, intensity, and containment difficulty…

The Integration section notes this combines ML predictions with Rothermel fire spread equations… referencing a well-established fire behavior model used by wildland firefighters worldwide.


The third card is Resource Optimization…

Model Type is Multi-objective Optimization…

This card lists several capabilities…

Optimal crew deployment recommendations… suggesting where to position firefighting teams based on predicted fire activity…

Equipment allocation based on fire severity predictions… ensuring bulldozers and air tankers are pre-positioned near high-risk areas…

Evacuation route planning using traffic models… helping emergency managers identify safe evacuation corridors before fires threaten communities…

Water source identification and priority ranking… mapping nearby lakes, rivers, and hydrants for firefighting access.


At the bottom of the page… a prominent button labeled View Analytics Dashboard links to the interactive charts we saw earlier…

This ML-Powered Analytics page demonstrates to Challenge Three judges that we're not just storing and serving raw data… we're providing actionable intelligence through advanced machine learning… directly supporting operational decision-making.


The third card is titled Secure Data Sharing…

Finally… Secure Data Sharing presents our comprehensive security implementation…

This addresses Challenge Three requirements for data governance… ensuring only authorized personnel can access sensitive fire incident data… while logging every query for compliance.

Below the header… three security feature sections detail our implementation…

The first section presents Role-Based Access Control with RBAC abbreviation…

A table displays three columns… Role, Access Level, and Permissions…

Starting with Administrator… this role has RESTRICTED access level… with permissions for full system access and user management…

Next… Data Scientist with CONFIDENTIAL access… able to access ML models, full data, and Jupyter notebooks…

Then… Analyst with SENSITIVE access… limited to reports, exports, and a subset of the data…

Business User with INTERNAL access… read-only access to dashboards and PDF exports…

Partner Agency also INTERNAL… able to access shared data and mutual aid information…

Finally… External Researcher with PUBLIC access… limited to API access and bulk downloads of non-sensitive data…

This table clearly demonstrates our least-privilege access model… where users only see data appropriate for their role.


The second section is Authentication and Encryption…

This lists five security mechanisms…

API Keys with ninety-day expiration and automatic rotation… preventing long-lived credentials from being compromised…

JWT Tokens for twenty-four-hour session tokens… requiring daily re-authentication…

TLS one point three for all data encrypted in transit… using the latest transport layer security protocol…

AES-two fifty-six for data encrypted at rest… military-grade encryption for stored datasets…

And MFA Ready indicating multi-factor authentication support… adding a second layer of security beyond passwords.


The third section is Comprehensive Audit Logging…

The text explains that every action is logged with five key attributes…

Who… capturing user ID, role, and IP address…

What… recording the action performed and resource accessed…

When… timestamping in PST timezone for consistent reporting…

Where… logging the endpoint, service, and geographic location…

Result… tracking success or failure with error details…

Retention shows seven years… meeting compliance requirements for government contracts and legal discovery…

This audit trail ensures accountability… allowing security teams to trace every data access back to a specific user at a specific time… critical for Challenge Three's data governance requirements.


At the bottom… a button labeled Security API Documentation links to the technical specifications for implementing these security controls in external systems.


## Features Grid - Bottom Row

The fourth card displays Global Partnerships…

It reads… Collaborative platform connecting fire agencies across Australia, Europe, Canada, and beyond…

This reinforces our international reach… facilitating data exchange between countries facing similar wildfire challenges.


The fifth card presents High-Performance APIs…

The text states… RESTful APIs with sub-second response times, bulk data operations, and flexible query capabilities…

This demonstrates our technical performance… meeting Challenge Three criteria for fast, scalable data access… handling thousands of API requests per hour.


Finally… the sixth card features Interactive Dashboards…

The description mentions… Custom visualization tools with geospatial mapping, time-series analysis, and real-time monitoring…

These are the role-specific dashboards for fire chiefs, analysts, and scientists… providing tailored views of the data.


## Featured Datasets Section

At the bottom of the page… we see a Featured Datasets section with three highlighted entries…

The first dataset is labeled CAL FIRE Incident Database two thousand twenty-four…

It shows forty-five point two Megabytes… updated daily… with sensitive access restrictions…

This contains detailed records of every wildfire incident in California… including ignition point, size, containment status, and resource deployment… restricted to CAL FIRE personnel and authorized partners.


Below that… the second dataset is Global MODIS Fire Detections…

Size is eight hundred ninety-two point one Megabytes… marked as real-time with public access…

This is our largest publicly available dataset… containing millions of fire hotspots detected by NASA satellites… updated continuously as new imagery arrives.


The third featured dataset shows Advanced Fire Risk Models…

Two hundred thirty-four point five Megabytes… updated monthly… requiring a research partnership for access…

These are machine learning models trained on historical fire data… predicting fire danger levels based on weather, vegetation, and topography… available to qualified research institutions through data use agreements.


## Why This Matters for Challenge Three

Challenge Three assesses our data consumption layer based on accessibility, security, and user experience…

This portal demonstrates all three requirements…

First… accessibility is proven through multiple interfaces… web portal, REST APIs, and interactive dashboards… serving diverse user types from fire chiefs to data scientists…

Second… security is implemented with role-based access control… ensuring the CAL FIRE Incident Database is restricted to authorized users… while public satellite data remains openly accessible…

Third… user experience is optimized with intuitive navigation… clear statistics… and categorized features… making it easy for non-technical users to find and download the data they need…

The data clearing house architecture shows this is a production-ready system designed for global deployment.


## Technical Architecture Behind the Portal

Behind this clean interface… the clearing house connects to our entire data pipeline…

When a user clicks Data Catalog… they're querying our PostgreSQL metadata catalog… which indexes every dataset by source, date range, and geographic coverage…

When they access Analytics Portal… they're hitting our FastAPI backend… which retrieves data from our multi-tier storage… HOT for recent fires… WARM for last ninety days… COLD for historical analysis…

When they call our APIs… requests flow through Kong gateway… which enforces rate limits… authenticates users… and logs every query for audit compliance…

And when they view dashboards… they're seeing real-time visualizations powered by the same Kafka streaming infrastructure that ingests satellite data… ensuring maps update within seconds of new fire detections…

This end-to-end integration… from ingestion to presentation… is what makes the Wildfire Intelligence Platform a complete solution for Challenge One, Two, and Three.